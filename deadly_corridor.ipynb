{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acfa1c81",
   "metadata": {},
   "source": [
    "1. Getting VizDoom Up and Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2299309a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: vizdoom in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.2.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from vizdoom) (2.2.5)\n",
      "Requirement already satisfied: pygame>=2.1.3 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from vizdoom) (2.6.1)\n",
      "Requirement already satisfied: gymnasium>=0.28.0 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from vizdoom) (1.1.1)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gymnasium>=0.28.0->vizdoom) (0.0.4)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\kando\\appdata\\roaming\\python\\python310\\site-packages (from gymnasium>=0.28.0->vizdoom) (4.13.2)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gymnasium>=0.28.0->vizdoom) (3.1.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install vizdoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48139cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'ViZDoom' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!cd github & git clone https://github.com/Farama-Foundation/ViZDoom.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3ac7f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import visdoom for game env\n",
    "from vizdoom import *\n",
    "# Import random for action sampling\n",
    "import random\n",
    "# Import time for sleeping\n",
    "import time\n",
    "# Import numpy for identity matrix creation\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3aaf11ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Game Setup\n",
    "game = DoomGame()\n",
    "# Set the game configuration file\n",
    "game.load_config(\"github\\ViZDoom\\scenarios\\deadly_corridor.cfg\")\n",
    "# Set the game scenario\n",
    "game.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b745ac62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the set of actions that the agent can take in the environment\n",
    "actions = np.identity(7, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97860173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward:  0.0\n",
      "Reward:  -0.78125\n",
      "Reward:  -2.458099365234375\n",
      "Reward:  -11.259750366210938\n",
      "Reward:  -1.44317626953125\n",
      "Reward:  7.0593719482421875\n",
      "Reward:  8.468719482421875\n",
      "Reward:  -1.1870269775390625\n",
      "Reward:  -2.4972381591796875\n",
      "Reward:  -1.196502685546875\n",
      "Reward:  -3.2650146484375\n",
      "Reward:  3.141845703125\n",
      "Reward:  8.061111450195312\n",
      "Reward:  6.7279052734375\n",
      "Reward:  4.5380096435546875\n",
      "Reward:  -3.83837890625\n",
      "Reward:  -4.553009033203125\n",
      "Reward:  -2.14349365234375\n",
      "Reward:  -11.0223388671875\n",
      "Reward:  -8.269027709960938\n",
      "Reward:  -0.0113067626953125\n",
      "Reward:  -0.009521484375\n",
      "Reward:  0.0\n",
      "Reward:  -0.0561370849609375\n",
      "Reward:  0.0\n",
      "Reward:  0.0\n",
      "Reward:  6.8990478515625\n",
      "Reward:  8.276397705078125\n",
      "Reward:  -1.3167572021484375\n",
      "Reward:  -6.1706695556640625\n",
      "Reward:  -5.78814697265625\n",
      "Reward:  -1.874481201171875\n",
      "Reward:  0.0\n",
      "Reward:  0.0\n",
      "Reward:  0.0\n",
      "Reward:  2.261077880859375\n",
      "Reward:  2.71240234375\n",
      "Reward:  1.8294525146484375\n",
      "Reward:  -5.87982177734375\n",
      "Reward:  -0.8848724365234375\n",
      "Reward:  -0.0469512939453125\n",
      "Reward:  0.0\n",
      "Reward:  0.0\n",
      "Reward:  0.0\n",
      "Reward:  0.0\n",
      "Reward:  7.1137542724609375\n",
      "Reward:  8.533950805664062\n",
      "Reward:  -1.3575897216796875\n",
      "Reward:  -101.33976745605469\n",
      "Result: -103.02728271484375\n",
      "Reward:  0.0\n",
      "Reward:  0.0\n",
      "Reward:  0.0\n",
      "Reward:  0.0\n",
      "Reward:  -15.892822265625\n",
      "Reward:  -0.0673370361328125\n",
      "Reward:  0.0\n",
      "Reward:  -0.0348663330078125\n",
      "Reward:  0.0\n",
      "Reward:  -0.002227783203125\n",
      "Reward:  0.622283935546875\n",
      "Reward:  0.7464141845703125\n",
      "Reward:  1.12567138671875\n",
      "Reward:  1.078765869140625\n",
      "Reward:  -1.987518310546875\n",
      "Reward:  -1.5240936279296875\n",
      "Reward:  0.0\n",
      "Reward:  -0.0621337890625\n",
      "Reward:  0.622283935546875\n",
      "Reward:  0.12396240234375\n",
      "Reward:  -100.13360595703125\n",
      "Result: -115.38522338867188\n",
      "Reward:  0.0\n",
      "Reward:  0.0\n",
      "Reward:  0.0\n",
      "Reward:  0.0\n",
      "Reward:  -13.295745849609375\n",
      "Reward:  -2.5908660888671875\n",
      "Reward:  0.0\n",
      "Reward:  0.0\n",
      "Reward:  0.0\n",
      "Reward:  -0.1029815673828125\n",
      "Reward:  0.0\n",
      "Reward:  1.8764190673828125\n",
      "Reward:  2.85821533203125\n",
      "Reward:  5.6868438720703125\n",
      "Reward:  2.0506134033203125\n",
      "Reward:  -0.591064453125\n",
      "Reward:  -0.3988037109375\n",
      "Reward:  -5.8196563720703125\n",
      "Reward:  -1.2899627685546875\n",
      "Reward:  2.0445098876953125\n",
      "Reward:  1.37896728515625\n",
      "Reward:  -3.957916259765625\n",
      "Reward:  -3.8318023681640625\n",
      "Reward:  0.0\n",
      "Reward:  5.4347381591796875\n",
      "Reward:  6.51971435546875\n",
      "Reward:  -7.5370025634765625\n",
      "Reward:  -4.4171905517578125\n",
      "Reward:  4.8877410888671875\n",
      "Reward:  10.827560424804688\n",
      "Reward:  9.910125732421875\n",
      "Reward:  6.68438720703125\n",
      "Reward:  4.50860595703125\n",
      "Reward:  -98.33026123046875\n",
      "Result: -77.49481201171875\n",
      "Reward:  0.0\n",
      "Reward:  -0.78125\n",
      "Reward:  -3.1559600830078125\n",
      "Reward:  -3.0179901123046875\n",
      "Reward:  -8.561599731445312\n",
      "Reward:  -0.1139068603515625\n",
      "Reward:  -0.3480377197265625\n",
      "Reward:  0.0\n",
      "Reward:  0.0\n",
      "Reward:  0.0\n",
      "Reward:  0.8306884765625\n",
      "Reward:  -0.841552734375\n",
      "Reward:  7.06011962890625\n",
      "Reward:  8.469589233398438\n",
      "Reward:  5.712799072265625\n",
      "Reward:  3.8532562255859375\n",
      "Reward:  2.59893798828125\n",
      "Reward:  1.7528533935546875\n",
      "Reward:  0.7922210693359375\n",
      "Reward:  -9.21307373046875\n",
      "Reward:  -9.332855224609375\n",
      "Reward:  -6.2952728271484375\n",
      "Reward:  -2.9964599609375\n",
      "Reward:  -1.3648681640625\n",
      "Reward:  -0.91461181640625\n",
      "Reward:  -0.1308135986328125\n",
      "Reward:  0.0\n",
      "Reward:  0.0\n",
      "Reward:  0.0\n",
      "Reward:  0.0\n",
      "Reward:  2.95843505859375\n",
      "Reward:  9.898422241210938\n",
      "Reward:  16.39337158203125\n",
      "Reward:  14.4031982421875\n",
      "Reward:  9.715072631835938\n",
      "Reward:  7.38873291015625\n",
      "Reward:  5.4226226806640625\n",
      "Reward:  3.6575469970703125\n",
      "Reward:  2.467010498046875\n",
      "Reward:  1.6639404296875\n",
      "Reward:  -4.9306488037109375\n",
      "Reward:  -6.785675048828125\n",
      "Reward:  -4.5771484375\n",
      "Reward:  -3.087493896484375\n",
      "Reward:  -2.082672119140625\n",
      "Reward:  -1.4048309326171875\n",
      "Reward:  -0.947662353515625\n",
      "Reward:  6.4441680908203125\n",
      "Reward:  -97.67660522460938\n",
      "Result: -57.0780029296875\n",
      "Reward:  0.0\n",
      "Reward:  0.0\n",
      "Reward:  0.0\n",
      "Reward:  2.2572784423828125\n",
      "Reward:  1.689300537109375\n",
      "Reward:  -14.725540161132812\n",
      "Reward:  -5.10955810546875\n",
      "Reward:  -0.0870819091796875\n",
      "Reward:  0.0\n",
      "Reward:  0.0\n",
      "Reward:  -0.000946044921875\n",
      "Reward:  0.0\n",
      "Reward:  0.0\n",
      "Reward:  0.0\n",
      "Reward:  -0.0130767822265625\n",
      "Reward:  0.0\n",
      "Reward:  0.0\n",
      "Reward:  0.0\n",
      "Reward:  7.0593719482421875\n",
      "Reward:  7.6327056884765625\n",
      "Reward:  3.873260498046875\n",
      "Reward:  -99.37396240234375\n",
      "Result: -96.79824829101562\n",
      "Reward:  0.0\n",
      "Reward:  0.0\n",
      "Reward:  0.0\n",
      "Reward:  0.0\n",
      "Reward:  -15.8289794921875\n",
      "Reward:  0.0\n",
      "Reward:  0.0\n",
      "Reward:  -0.0727691650390625\n",
      "Reward:  -0.0343017578125\n",
      "Reward:  0.824737548828125\n",
      "Reward:  0.150054931640625\n",
      "Reward:  0.4979095458984375\n",
      "Reward:  7.8341064453125\n",
      "Reward:  16.050704956054688\n",
      "Reward:  14.533477783203125\n",
      "Reward:  11.462188720703125\n",
      "Reward:  12.328018188476562\n",
      "Reward:  9.508712768554688\n",
      "Reward:  4.2881011962890625\n",
      "Reward:  -0.2078704833984375\n",
      "Reward:  -100.0770263671875\n",
      "Result: -38.74293518066406\n",
      "Reward:  0.0\n",
      "Reward:  -0.78125\n",
      "Reward:  -9.571868896484375\n",
      "Reward:  -5.59613037109375\n",
      "Reward:  4.3677520751953125\n",
      "Reward:  6.653167724609375\n",
      "Reward:  4.457489013671875\n",
      "Reward:  -1.0037841796875\n",
      "Reward:  5.35052490234375\n",
      "Reward:  7.231842041015625\n",
      "Reward:  4.8778839111328125\n",
      "Reward:  8.906814575195312\n",
      "Reward:  7.5933380126953125\n",
      "Reward:  0.607757568359375\n",
      "Reward:  -1.8818206787109375\n",
      "Reward:  -4.81353759765625\n",
      "Reward:  -5.0691680908203125\n",
      "Reward:  -9.790634155273438\n",
      "Reward:  -16.32110595703125\n",
      "Reward:  -11.157241821289062\n",
      "Reward:  -97.96652221679688\n",
      "Result: -113.906494140625\n",
      "Reward:  0.0\n",
      "Reward:  0.0\n",
      "Reward:  -10.62677001953125\n",
      "Reward:  -5.3488311767578125\n",
      "Reward:  0.0\n",
      "Reward:  7.1137542724609375\n",
      "Reward:  6.8040771484375\n",
      "Reward:  -3.1720123291015625\n",
      "Reward:  -5.875396728515625\n",
      "Reward:  -4.464019775390625\n",
      "Reward:  -0.4012451171875\n",
      "Reward:  -100.0\n",
      "Result: -115.97044372558594\n",
      "Reward:  0.0\n",
      "Reward:  0.0\n",
      "Reward:  -1.9029541015625\n",
      "Reward:  -13.759414672851562\n",
      "Reward:  -0.335723876953125\n",
      "Reward:  0.0\n",
      "Reward:  0.0\n",
      "Reward:  1.03826904296875\n",
      "Reward:  0.207183837890625\n",
      "Reward:  0.6326751708984375\n",
      "Reward:  0.971893310546875\n",
      "Reward:  -2.8284454345703125\n",
      "Reward:  0.0\n",
      "Reward:  -0.019927978515625\n",
      "Reward:  0.0\n",
      "Reward:  0.0\n",
      "Reward:  0.0\n",
      "Reward:  0.0\n",
      "Reward:  0.0\n",
      "Reward:  0.0\n",
      "Reward:  0.0\n",
      "Reward:  1.2447357177734375\n",
      "Reward:  2.7379608154296875\n",
      "Reward:  1.9458465576171875\n",
      "Reward:  1.880615234375\n",
      "Reward:  2.237823486328125\n",
      "Reward:  2.57794189453125\n",
      "Reward:  -4.43096923828125\n",
      "Reward:  -6.3956451416015625\n",
      "Reward:  -1.7666778564453125\n",
      "Reward:  0.0\n",
      "Reward:  0.0\n",
      "Reward:  0.0\n",
      "Reward:  0.0\n",
      "Reward:  0.0\n",
      "Reward:  -100.01106262207031\n",
      "Result: -115.97587585449219\n",
      "Reward:  0.0\n",
      "Reward:  0.0\n",
      "Reward:  -7.11376953125\n",
      "Reward:  -1.4203948974609375\n",
      "Reward:  -7.2918548583984375\n",
      "Reward:  6.7259368896484375\n",
      "Reward:  15.098526000976562\n",
      "Reward:  6.8316650390625\n",
      "Reward:  0.9006805419921875\n",
      "Reward:  7.5064849853515625\n",
      "Reward:  7.026763916015625\n",
      "Reward:  -3.031097412109375\n",
      "Reward:  -5.667694091796875\n",
      "Reward:  -3.8230438232421875\n",
      "Reward:  -2.5788116455078125\n",
      "Reward:  -1.73956298828125\n",
      "Reward:  -0.1301422119140625\n",
      "Reward:  -0.583465576171875\n",
      "Reward:  -7.9710693359375\n",
      "Reward:  -2.0388641357421875\n",
      "Reward:  2.316009521484375\n",
      "Reward:  1.562042236328125\n",
      "Reward:  1.0534820556640625\n",
      "Reward:  0.7104644775390625\n",
      "Reward:  0.34765625\n",
      "Reward:  7.2627716064453125\n",
      "Reward:  3.11029052734375\n",
      "Reward:  0.364471435546875\n",
      "Reward:  -1.408599853515625\n",
      "Reward:  -3.4733734130859375\n",
      "Reward:  -1.557464599609375\n",
      "Reward:  -7.0824127197265625\n",
      "Reward:  -15.301513671875\n",
      "Reward:  -4.5804290771484375\n",
      "Reward:  -0.01800537109375\n",
      "Reward:  0.0\n",
      "Reward:  0.0\n",
      "Reward:  0.8306884765625\n",
      "Reward:  0.9964752197265625\n",
      "Reward:  1.50274658203125\n",
      "Reward:  1.1460113525390625\n",
      "Reward:  0.5411834716796875\n",
      "Reward:  7.4752655029296875\n",
      "Reward:  5.826263427734375\n",
      "Reward:  -3.242431640625\n",
      "Reward:  -11.547378540039062\n",
      "Reward:  -3.444610595703125\n",
      "Reward:  0.2037811279296875\n",
      "Reward:  0.191925048828125\n",
      "Reward:  0.0\n",
      "Reward:  -0.4118804931640625\n",
      "Reward:  0.0\n",
      "Reward:  6.8441619873046875\n",
      "Reward:  8.193389892578125\n",
      "Reward:  -4.516082763671875\n",
      "Reward:  -8.739990234375\n",
      "Reward:  -1.8488311767578125\n",
      "Reward:  0.0\n",
      "Reward:  0.0\n",
      "Reward:  0.0\n",
      "Reward:  0.0\n",
      "Reward:  0.0\n",
      "Reward:  5.0875396728515625\n",
      "Reward:  -0.6084442138671875\n",
      "Reward:  -3.560394287109375\n",
      "Reward:  -0.57720947265625\n",
      "Reward:  -0.32373046875\n",
      "Reward:  0.0\n",
      "Reward:  0.0\n",
      "Reward:  0.0\n",
      "Reward:  0.0\n",
      "Reward:  0.0\n",
      "Reward:  0.413482666015625\n",
      "Reward:  0.0825042724609375\n",
      "Reward:  -0.1615753173828125\n",
      "Reward:  -0.33416748046875\n",
      "Reward:  0.0\n",
      "Reward:  0.0\n",
      "Reward:  -0.0229339599609375\n",
      "Reward:  7.099822998046875\n",
      "Reward:  15.617095947265625\n",
      "Reward:  12.08099365234375\n",
      "Reward:  3.240478515625\n",
      "Reward:  2.281494140625\n",
      "Reward:  2.599334716796875\n",
      "Reward:  3.30523681640625\n",
      "Reward:  2.751007080078125\n",
      "Reward:  1.8555145263671875\n",
      "Reward:  -0.805908203125\n",
      "Reward:  -3.6815338134765625\n",
      "Reward:  2.2073211669921875\n",
      "Reward:  -0.6623382568359375\n",
      "Reward:  -8.291351318359375\n",
      "Reward:  -2.37255859375\n",
      "Reward:  -0.0798797607421875\n",
      "Reward:  -1.0728607177734375\n",
      "Reward:  1.3336944580078125\n",
      "Reward:  4.037353515625\n",
      "Reward:  10.58502197265625\n",
      "Reward:  9.7041015625\n",
      "Reward:  6.3647613525390625\n",
      "Reward:  9.9805908203125\n",
      "Reward:  9.718734741210938\n",
      "Reward:  1.8198394775390625\n",
      "Reward:  -5.99493408203125\n",
      "Reward:  -9.30133056640625\n",
      "Reward:  -8.394454956054688\n",
      "Reward:  -5.6623077392578125\n",
      "Reward:  -3.819366455078125\n",
      "Reward:  -2.5763092041015625\n",
      "Reward:  -1.73785400390625\n",
      "Reward:  -1.1722869873046875\n",
      "Reward:  -6.847259521484375\n",
      "Reward:  -11.37713623046875\n",
      "Reward:  -9.553115844726562\n",
      "Reward:  -10.021835327148438\n",
      "Reward:  -13.029190063476562\n",
      "Reward:  3.57794189453125\n",
      "Reward:  7.8702239990234375\n",
      "Reward:  7.1874237060546875\n",
      "Reward:  6.726318359375\n",
      "Reward:  2.0765533447265625\n",
      "Reward:  5.5779571533203125\n",
      "Reward:  6.942718505859375\n",
      "Reward:  4.6828460693359375\n",
      "Reward:  2.946319580078125\n",
      "Reward:  1.956268310546875\n",
      "Reward:  1.31939697265625\n",
      "Reward:  0.8898468017578125\n",
      "Reward:  0.60009765625\n",
      "Reward:  0.404632568359375\n",
      "Reward:  0.272857666015625\n",
      "Reward:  2.8389434814453125\n",
      "Reward:  0.5665435791015625\n",
      "Reward:  -1.1088714599609375\n",
      "Reward:  6.03338623046875\n",
      "Reward:  1.94976806640625\n",
      "Reward:  -0.6919708251953125\n",
      "Reward:  -7.460418701171875\n",
      "Reward:  -15.698440551757812\n",
      "Reward:  -14.261520385742188\n",
      "Reward:  -2.8383331298828125\n",
      "Reward:  8.427978515625\n",
      "Reward:  9.183929443359375\n",
      "Reward:  6.6113433837890625\n",
      "Reward:  -1.8805389404296875\n",
      "Reward:  2.0522918701171875\n",
      "Reward:  -1.9368438720703125\n",
      "Reward:  -3.2984161376953125\n",
      "Reward:  6.474456787109375\n",
      "Reward:  8.039535522460938\n",
      "Reward:  5.4226837158203125\n",
      "Reward:  0.259613037109375\n",
      "Reward:  4.5584564208984375\n",
      "Reward:  0.1456146240234375\n",
      "Reward:  0.256988525390625\n",
      "Reward:  1.9576263427734375\n",
      "Reward:  -1.326904296875\n",
      "Reward:  -2.2852630615234375\n",
      "Reward:  -1.5415496826171875\n",
      "Reward:  -0.6264190673828125\n",
      "Reward:  0.2079925537109375\n",
      "Reward:  0.35491943359375\n",
      "Reward:  -0.41351318359375\n",
      "Reward:  -0.90966796875\n",
      "Reward:  -0.64654541015625\n",
      "Reward:  0.0\n",
      "Reward:  0.0\n",
      "Reward:  1.2447357177734375\n",
      "Reward:  2.7379608154296875\n",
      "Reward:  3.5418701171875\n",
      "Reward:  9.113876342773438\n",
      "Reward:  9.81988525390625\n",
      "Reward:  -0.4768829345703125\n",
      "Reward:  -4.05047607421875\n",
      "Reward:  -9.832183837890625\n",
      "Reward:  -10.360565185546875\n",
      "Reward:  -6.98846435546875\n",
      "Reward:  -4.7139129638671875\n",
      "Reward:  -3.1797332763671875\n",
      "Reward:  -2.1448974609375\n",
      "Reward:  -1.446868896484375\n",
      "Reward:  -0.9760589599609375\n",
      "Reward:  -1.8892669677734375\n",
      "Reward:  -0.50689697265625\n",
      "Reward:  5.448272705078125\n",
      "Reward:  -0.1629486083984375\n",
      "Reward:  -3.7820892333984375\n",
      "Reward:  -3.6697540283203125\n",
      "Reward:  -101.00991821289062\n",
      "Result: -77.70603942871094\n"
     ]
    }
   ],
   "source": [
    "episode = 10\n",
    "for episode in range(episode):\n",
    "    # Start the game\n",
    "    game.new_episode()\n",
    "    # Run the game until it is over\n",
    "    while not game.is_episode_finished():\n",
    "        # Get the state of the game\n",
    "        state = game.get_state()\n",
    "        # Get the current frame from the state\n",
    "        frame = state.screen_buffer\n",
    "        # Sample a random action from the action space\n",
    "        action = random.choice(actions)\n",
    "        # Get the current reward from the state\n",
    "        info = state.game_variables[0]\n",
    "        # Perform the action in the game environment\n",
    "        reward = game.make_action(action, 4)\n",
    "        # Print the reward\n",
    "        print(\"Reward: \", reward)\n",
    "        # Sleep for a short time to control the speed of the agent's actions\n",
    "        time.sleep(0.1)\n",
    "    print('Result:', game.get_total_reward())\n",
    "    time.sleep(2)\n",
    "# Close the game when done\n",
    "game.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47822af7",
   "metadata": {},
   "source": [
    "2. Converting it to a Gym Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8657e71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: gymnasium in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gymnasium) (0.0.4)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\kando\\appdata\\roaming\\python\\python310\\site-packages (from gymnasium) (4.13.2)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gymnasium) (2.2.5)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gymnasium) (3.1.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install gymnasium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "901849dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: opencv-python in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from opencv-python) (2.2.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56510063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: pip in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (23.0.1)\n",
      "Collecting pip\n",
      "  Downloading pip-25.1.1-py3-none-any.whl (1.8 MB)\n",
      "     ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.0/1.8 MB 1.3 MB/s eta 0:00:02\n",
      "     -- ------------------------------------- 0.1/1.8 MB 871.5 kB/s eta 0:00:02\n",
      "     --- ------------------------------------ 0.2/1.8 MB 1.0 MB/s eta 0:00:02\n",
      "     ----- ---------------------------------- 0.3/1.8 MB 1.3 MB/s eta 0:00:02\n",
      "     --------- ------------------------------ 0.4/1.8 MB 1.8 MB/s eta 0:00:01\n",
      "     ------------- -------------------------- 0.6/1.8 MB 2.1 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 0.8/1.8 MB 2.4 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 1.1/1.8 MB 2.9 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 1.4/1.8 MB 3.4 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 1.7/1.8 MB 3.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.8/1.8 MB 3.7 MB/s eta 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: To modify pip, please run the following command:\n",
      "C:\\Users\\kando\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: matplotlib in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.10.1)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (2.2.5)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kando\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\kando\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kando\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install matplotlib --no-cache-dir --index-url https://pypi.org/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75448346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: torch in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.7.0+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.22.0+cu118)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.7.0+cu118)\n",
      "Requirement already satisfied: networkx in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\kando\\appdata\\roaming\\python\\python310\\site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (11.2.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (2.2.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4197547b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: stable-baselines3[extra] in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stable-baselines3[extra]) (3.1.1)\n",
      "Requirement already satisfied: torch<3.0,>=2.3 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stable-baselines3[extra]) (2.7.0+cu118)\n",
      "Requirement already satisfied: numpy<3.0,>=1.20 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stable-baselines3[extra]) (2.2.5)\n",
      "Requirement already satisfied: gymnasium<1.2.0,>=0.29.1 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stable-baselines3[extra]) (1.1.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stable-baselines3[extra]) (2.2.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stable-baselines3[extra]) (3.10.1)\n",
      "Requirement already satisfied: pygame in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stable-baselines3[extra]) (2.6.1)\n",
      "Requirement already satisfied: rich in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stable-baselines3[extra]) (14.0.0)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stable-baselines3[extra]) (4.11.0.86)\n",
      "Requirement already satisfied: pillow in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stable-baselines3[extra]) (11.2.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stable-baselines3[extra]) (4.67.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\kando\\appdata\\roaming\\python\\python310\\site-packages (from stable-baselines3[extra]) (7.0.0)\n",
      "Requirement already satisfied: tensorboard>=2.9.1 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stable-baselines3[extra]) (2.19.0)\n",
      "Requirement already satisfied: ale-py>=0.9.0 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stable-baselines3[extra]) (0.11.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\kando\\appdata\\roaming\\python\\python310\\site-packages (from ale-py>=0.9.0->stable-baselines3[extra]) (4.13.2)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gymnasium<1.2.0,>=0.29.1->stable-baselines3[extra]) (0.0.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (65.5.0)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (6.30.2)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.71.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.2.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.1.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.8)\n",
      "Requirement already satisfied: packaging in c:\\users\\kando\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (25.0)\n",
      "Requirement already satisfied: six>1.9 in c:\\users\\kando\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.17.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.1.6)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (1.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.18.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (2025.3.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\kando\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib->stable-baselines3[extra]) (2.9.0.post0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (1.3.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (1.4.8)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (4.57.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (0.12.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->stable-baselines3[extra]) (2025.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->stable-baselines3[extra]) (2025.2)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\kando\\appdata\\roaming\\python\\python310\\site-packages (from rich->stable-baselines3[extra]) (2.19.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rich->stable-baselines3[extra]) (3.0.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\kando\\appdata\\roaming\\python\\python310\\site-packages (from tqdm->stable-baselines3[extra]) (0.4.6)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy>=1.13.3->torch<3.0,>=2.3->stable-baselines3[extra]) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install stable-baselines3[extra]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06810963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import environment for OpenAI Gym\n",
    "import gymnasium as gym\n",
    "from gym import Env\n",
    "from gym import spaces\n",
    "from gym.spaces import Discrete, Box\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from stable_baselines3.common.env_checker import check_env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db66899d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "import cv2\n",
    "from vizdoom import DoomGame\n",
    "\n",
    "class VizDoomGym(gym.Env):\n",
    "    def __init__(self, render=False, config=\"github\\ViZDoom\\scenarios\\deadly_corridor_level_1.cfg\"):\n",
    "        super().__init__()\n",
    "\n",
    "        self.game = DoomGame()\n",
    "        self.game.load_config(config)\n",
    "        self.game.set_window_visible(render)\n",
    "        self.game.init()\n",
    "\n",
    "        # Gymnasium expects these to be from gymnasium.spaces\n",
    "        self.observation_space = spaces.Box(low=0, high=255, shape=(100, 160, 1), dtype=np.uint8)\n",
    "        self.action_space = spaces.Discrete(7)\n",
    "        \n",
    "        # Game variables: HEALTH DAMAGE_TAKEN HITCOUNT SELECTED_WEAPON_AMMO\n",
    "        self.damage_taken = 0\n",
    "        self.hitcount = 0\n",
    "        self.selected_weapon_ammo = 52\n",
    "\n",
    "    def step(self, action):\n",
    "        actions = np.identity(7, dtype=np.uint8)\n",
    "        movement_reward = self.game.make_action(actions[action], 4)\n",
    "        \n",
    "        reward = 0\n",
    "\n",
    "        done = self.game.is_episode_finished()\n",
    "        truncated = False  # No time limit-based truncation\n",
    "        if not done and self.game.get_state():\n",
    "            state = self.game.get_state().screen_buffer\n",
    "            state = self.grayscale(state)\n",
    "            \n",
    "            # Reward structure\n",
    "            game_variables = self.game.get_state().game_variables\n",
    "            health, damage_taken, hitcount, ammo = game_variables\n",
    "            \n",
    "            # Calculate reward based on game variables\n",
    "            damage_taken_delta = -damage_taken + self.damage_taken\n",
    "            self.damage_taken = damage_taken\n",
    "            hitcount_delta = hitcount - self.hitcount\n",
    "            self.hitcount = hitcount\n",
    "            ammo_delta = ammo - self.selected_weapon_ammo\n",
    "            self.selected_weapon_ammo = ammo\n",
    "            \n",
    "            reward = movement_reward + damage_taken_delta*10 + hitcount_delta*200 + ammo_delta\n",
    "            \n",
    "            info = ammo\n",
    "            \n",
    "        else:\n",
    "            state = np.zeros(self.observation_space.shape, dtype=np.uint8)\n",
    "            info = 0\n",
    "            \n",
    "        info = {\"info\":info}\n",
    "        done = self.game.is_episode_finished()\n",
    "\n",
    "        return state, reward, done, truncated, info\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "\n",
    "        if not self.game.is_running():\n",
    "            self.game.init()\n",
    "\n",
    "        self.game.new_episode()\n",
    "\n",
    "        state = self.game.get_state()\n",
    "        if state is None:\n",
    "            raise RuntimeError(\"Failed to get initial game state.\")\n",
    "\n",
    "        return self.grayscale(state.screen_buffer), {}\n",
    "\n",
    "\n",
    "    def render(self):\n",
    "        pass  # You can implement frame rendering if needed\n",
    "\n",
    "    def close(self):\n",
    "        self.game.close()\n",
    "\n",
    "    def grayscale(self, observation):\n",
    "        gray = cv2.cvtColor(np.moveaxis(observation, 0, -1), cv2.COLOR_BGR2GRAY)\n",
    "        resize = cv2.resize(gray, (160, 100), interpolation=cv2.INTER_CUBIC)\n",
    "        state = np.reshape(resize, (100, 160, 1))  # Fixed shape\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b5960c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.env_checker import check_env\n",
    "\n",
    "env = VizDoomGym(render=True)\n",
    "check_env(env)  # Should pass with no errors now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "765385d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31969eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import os for file navigation\n",
    "import os\n",
    "#Import callback class from sb3\n",
    "from stable_baselines3.common.callbacks import BaseCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49d2df3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainAndLoggingCallback(BaseCallback):\n",
    "    \n",
    "    def __init__(self, check_freq, save_path, verbose=1):\n",
    "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "        \n",
    "    def _init_callback(self):\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "            \n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls))\n",
    "            self.model.save(model_path)\n",
    "            \n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "185ca1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = './train/train_corridor'\n",
    "LOG_DIR = './logs/log_corridor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db3696f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = TrainAndLoggingCallback(check_freq=10000, save_path=CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6228736",
   "metadata": {},
   "source": [
    "Training the model using curriculum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e2cd83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cee1b9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render = false\n",
    "env = VizDoomGym(config=\"github\\ViZDoom\\scenarios\\deadly_corridor_level_1.cfg\", render=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e0ac2bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "model = PPO(\"CnnPolicy\", env, verbose=1, learning_rate=0.00001, tensorboard_log=LOG_DIR, n_steps=8192, clip_range=0.1, gamma= 0.95, gae_lambda=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a00772dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./logs/log_corridor\\PPO_1\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 243      |\n",
      "|    ep_rew_mean     | 74.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 31       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 259      |\n",
      "|    total_timesteps | 8192     |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 211          |\n",
      "|    ep_rew_mean          | 104          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 32           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 504          |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035749474 |\n",
      "|    clip_fraction        | 0.165        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.94        |\n",
      "|    explained_variance   | 5.26e-05     |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.59e+03     |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00567     |\n",
      "|    value_loss           | 5.14e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 169          |\n",
      "|    ep_rew_mean          | 151          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 33           |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 726          |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023029263 |\n",
      "|    clip_fraction        | 0.104        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.94        |\n",
      "|    explained_variance   | 0.0106       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 2.21e+03     |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00212     |\n",
      "|    value_loss           | 6.67e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 146          |\n",
      "|    ep_rew_mean          | 211          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 34           |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 957          |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024917885 |\n",
      "|    clip_fraction        | 0.152        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.93        |\n",
      "|    explained_variance   | 0.0415       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 2.87e+03     |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00259     |\n",
      "|    value_loss           | 8.6e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 129          |\n",
      "|    ep_rew_mean          | 210          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 34           |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 1193         |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030180449 |\n",
      "|    clip_fraction        | 0.174        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.92        |\n",
      "|    explained_variance   | 0.0943       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 2.67e+03     |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0038      |\n",
      "|    value_loss           | 7.73e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 108          |\n",
      "|    ep_rew_mean          | 251          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 34           |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 1433         |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024587242 |\n",
      "|    clip_fraction        | 0.136        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.91        |\n",
      "|    explained_variance   | 0.125        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 2.89e+03     |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.00213     |\n",
      "|    value_loss           | 9.72e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 311         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 34          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 1662        |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002780328 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.177       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 7.53e+03    |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00341    |\n",
      "|    value_loss           | 1.05e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 93.2         |\n",
      "|    ep_rew_mean          | 329          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 33           |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 1985         |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027370602 |\n",
      "|    clip_fraction        | 0.193        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.89        |\n",
      "|    explained_variance   | 0.206        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 3.13e+03     |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.00245     |\n",
      "|    value_loss           | 1.11e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 87.8         |\n",
      "|    ep_rew_mean          | 302          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 32           |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 2234         |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034620466 |\n",
      "|    clip_fraction        | 0.217        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.86        |\n",
      "|    explained_variance   | 0.242        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 5.69e+03     |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.00255     |\n",
      "|    value_loss           | 1.12e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 88.5         |\n",
      "|    ep_rew_mean          | 368          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 33           |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 2478         |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052736974 |\n",
      "|    clip_fraction        | 0.195        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.86        |\n",
      "|    explained_variance   | 0.226        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 6.16e+03     |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00167     |\n",
      "|    value_loss           | 1.14e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 93.5         |\n",
      "|    ep_rew_mean          | 428          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 31           |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 2860         |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028680179 |\n",
      "|    clip_fraction        | 0.196        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.84        |\n",
      "|    explained_variance   | 0.245        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 4.62e+03     |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.00159     |\n",
      "|    value_loss           | 1.24e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 82.7         |\n",
      "|    ep_rew_mean          | 444          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 31           |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 3102         |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030066324 |\n",
      "|    clip_fraction        | 0.221        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.82        |\n",
      "|    explained_variance   | 0.258        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 8.18e+03     |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00222     |\n",
      "|    value_loss           | 1.15e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 75.9         |\n",
      "|    ep_rew_mean          | 489          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 31           |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 3333         |\n",
      "|    total_timesteps      | 106496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036484487 |\n",
      "|    clip_fraction        | 0.262        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.78        |\n",
      "|    explained_variance   | 0.275        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 4.75e+03     |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.00411     |\n",
      "|    value_loss           | 1.29e+04     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x22c5ec0cc40>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=100000, callback=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "80a02385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Logging to ./logs/log_corridor\\PPO_2\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 42.8     |\n",
      "|    ep_rew_mean     | 317      |\n",
      "| time/              |          |\n",
      "|    fps             | 34       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 235      |\n",
      "|    total_timesteps | 8192     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 43.5       |\n",
      "|    ep_rew_mean          | 369        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 31         |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 527        |\n",
      "|    total_timesteps      | 16384      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00357995 |\n",
      "|    clip_fraction        | 0.193      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.69      |\n",
      "|    explained_variance   | 0.294      |\n",
      "|    learning_rate        | 1e-05      |\n",
      "|    loss                 | 1.78e+04   |\n",
      "|    n_updates            | 140        |\n",
      "|    policy_gradient_loss | -0.000925  |\n",
      "|    value_loss           | 2.77e+04   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 40.7         |\n",
      "|    ep_rew_mean          | 335          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 28           |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 866          |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037131342 |\n",
      "|    clip_fraction        | 0.208        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.64        |\n",
      "|    explained_variance   | 0.377        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.25e+04     |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | 0.00122      |\n",
      "|    value_loss           | 2.74e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 39.1         |\n",
      "|    ep_rew_mean          | 352          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 27           |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 1206         |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037887075 |\n",
      "|    clip_fraction        | 0.232        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.62        |\n",
      "|    explained_variance   | 0.433        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.35e+04     |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | 0.000244     |\n",
      "|    value_loss           | 2.54e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 38.7         |\n",
      "|    ep_rew_mean          | 324          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 26           |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 1540         |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038801674 |\n",
      "|    clip_fraction        | 0.239        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.58        |\n",
      "|    explained_variance   | 0.474        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 8.5e+03      |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | 0.00162      |\n",
      "|    value_loss           | 2.51e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 40.1        |\n",
      "|    ep_rew_mean          | 341         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 26          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 1878        |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005353393 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.62       |\n",
      "|    explained_variance   | 0.528       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 9.58e+03    |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | 0.000397    |\n",
      "|    value_loss           | 2.22e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 40.5         |\n",
      "|    ep_rew_mean          | 358          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 26           |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 2202         |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039642244 |\n",
      "|    clip_fraction        | 0.249        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.62        |\n",
      "|    explained_variance   | 0.559        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.02e+04     |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | 0.000698     |\n",
      "|    value_loss           | 2.25e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 38.5        |\n",
      "|    ep_rew_mean          | 346         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 26          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 2451        |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004355143 |\n",
      "|    clip_fraction        | 0.257       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.63       |\n",
      "|    explained_variance   | 0.558       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 1.25e+04    |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | 0.00195     |\n",
      "|    value_loss           | 2.07e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 40.8         |\n",
      "|    ep_rew_mean          | 442          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 27           |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 2704         |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036047825 |\n",
      "|    clip_fraction        | 0.213        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.58        |\n",
      "|    explained_variance   | 0.576        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.46e+04     |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | 0.00151      |\n",
      "|    value_loss           | 2.09e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 38          |\n",
      "|    ep_rew_mean          | 416         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 2958        |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004991167 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.51       |\n",
      "|    explained_variance   | 0.586       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 1.18e+04    |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | 0.00051     |\n",
      "|    value_loss           | 2.14e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 38.7         |\n",
      "|    ep_rew_mean          | 457          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 28           |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 3211         |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043813847 |\n",
      "|    clip_fraction        | 0.232        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | 0.554        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.6e+04      |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | 0.000833     |\n",
      "|    value_loss           | 2.21e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 37.8        |\n",
      "|    ep_rew_mean          | 515         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 28          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 3450        |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004222951 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.39       |\n",
      "|    explained_variance   | 0.574       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 1.24e+04    |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | 0.000792    |\n",
      "|    value_loss           | 2.23e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 36.1         |\n",
      "|    ep_rew_mean          | 531          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 28           |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 3681         |\n",
      "|    total_timesteps      | 106496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025769507 |\n",
      "|    clip_fraction        | 0.17         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.29        |\n",
      "|    explained_variance   | 0.534        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.76e+04     |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | 0.000895     |\n",
      "|    value_loss           | 2.35e+04     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x22c5ec0cc40>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = VizDoomGym(config=\"github\\ViZDoom\\scenarios\\deadly_corridor_level_2.cfg\", render=False)\n",
    "model.set_env(env)\n",
    "model.learn(total_timesteps=100000, callback=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5f93b1b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Logging to ./logs/log_corridor\\PPO_3\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 35.4     |\n",
      "|    ep_rew_mean     | 498      |\n",
      "| time/              |          |\n",
      "|    fps             | 38       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 215      |\n",
      "|    total_timesteps | 8192     |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 35.8         |\n",
      "|    ep_rew_mean          | 521          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 35           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 465          |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029200586 |\n",
      "|    clip_fraction        | 0.16         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.23        |\n",
      "|    explained_variance   | 0.53         |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.31e+04     |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | 0.00122      |\n",
      "|    value_loss           | 2.56e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 36.3         |\n",
      "|    ep_rew_mean          | 547          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 34           |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 719          |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032499451 |\n",
      "|    clip_fraction        | 0.168        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.19        |\n",
      "|    explained_variance   | 0.557        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 6.83e+03     |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | 0.00193      |\n",
      "|    value_loss           | 2.4e+04      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 39           |\n",
      "|    ep_rew_mean          | 579          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 32           |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 994          |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033622365 |\n",
      "|    clip_fraction        | 0.174        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.18        |\n",
      "|    explained_variance   | 0.547        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.11e+04     |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | 0.00101      |\n",
      "|    value_loss           | 2.31e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 38.1         |\n",
      "|    ep_rew_mean          | 582          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 32           |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 1248         |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037047002 |\n",
      "|    clip_fraction        | 0.164        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.18        |\n",
      "|    explained_variance   | 0.551        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 6.18e+03     |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | 0.000159     |\n",
      "|    value_loss           | 2.3e+04      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 34.5        |\n",
      "|    ep_rew_mean          | 564         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 32          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 1497        |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003715924 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | 0.555       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 1.8e+04     |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | 0.000303    |\n",
      "|    value_loss           | 2.33e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 35.8         |\n",
      "|    ep_rew_mean          | 597          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 32           |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 1751         |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034786868 |\n",
      "|    clip_fraction        | 0.158        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.1         |\n",
      "|    explained_variance   | 0.55         |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.1e+04      |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | 0.00139      |\n",
      "|    value_loss           | 2.39e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 33.3         |\n",
      "|    ep_rew_mean          | 590          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 32           |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 1995         |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024192855 |\n",
      "|    clip_fraction        | 0.137        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0.533        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.1e+04      |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | 0.00167      |\n",
      "|    value_loss           | 2.44e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33          |\n",
      "|    ep_rew_mean          | 625         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 32          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 2236        |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002836336 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.983      |\n",
      "|    explained_variance   | 0.546       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 9.86e+03    |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | 0.00147     |\n",
      "|    value_loss           | 2.45e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.2        |\n",
      "|    ep_rew_mean          | 619         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 33          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 2478        |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003962785 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.919      |\n",
      "|    explained_variance   | 0.538       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 1.08e+04    |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | 0.00112     |\n",
      "|    value_loss           | 2.51e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32.7         |\n",
      "|    ep_rew_mean          | 614          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 33           |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 2723         |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029881243 |\n",
      "|    clip_fraction        | 0.111        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.864       |\n",
      "|    explained_variance   | 0.552        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.26e+04     |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | 0.00153      |\n",
      "|    value_loss           | 2.5e+04      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 33.7         |\n",
      "|    ep_rew_mean          | 683          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 33           |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 2961         |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018958268 |\n",
      "|    clip_fraction        | 0.116        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.868       |\n",
      "|    explained_variance   | 0.525        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.03e+04     |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | 0.00146      |\n",
      "|    value_loss           | 2.51e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32.6         |\n",
      "|    ep_rew_mean          | 679          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 33           |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 3216         |\n",
      "|    total_timesteps      | 106496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022957027 |\n",
      "|    clip_fraction        | 0.104        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.795       |\n",
      "|    explained_variance   | 0.539        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.67e+04     |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | 0.00158      |\n",
      "|    value_loss           | 2.38e+04     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x22c5ec0cc40>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = VizDoomGym(config=\"github\\ViZDoom\\scenarios\\deadly_corridor_level_3.cfg\", render=False)\n",
    "model.set_env(env)\n",
    "model.learn(total_timesteps=100000, callback=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cde0c290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Logging to ./logs/log_corridor\\PPO_4\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.6     |\n",
      "|    ep_rew_mean     | 648      |\n",
      "| time/              |          |\n",
      "|    fps             | 35       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 232      |\n",
      "|    total_timesteps | 8192     |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32.2         |\n",
      "|    ep_rew_mean          | 675          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 33           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 487          |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021136873 |\n",
      "|    clip_fraction        | 0.0995       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.752       |\n",
      "|    explained_variance   | 0.524        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 6.92e+03     |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | 0.00107      |\n",
      "|    value_loss           | 2.56e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31          |\n",
      "|    ep_rew_mean          | 678         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 33          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 743         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002328304 |\n",
      "|    clip_fraction        | 0.0918      |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.724      |\n",
      "|    explained_variance   | 0.53        |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 1.48e+04    |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | 0.00098     |\n",
      "|    value_loss           | 2.56e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29.8         |\n",
      "|    ep_rew_mean          | 647          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 32           |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 998          |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018244211 |\n",
      "|    clip_fraction        | 0.0869       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.695       |\n",
      "|    explained_variance   | 0.522        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.55e+04     |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | 0.00117      |\n",
      "|    value_loss           | 2.63e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32.2         |\n",
      "|    ep_rew_mean          | 688          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 32           |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 1250         |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024701753 |\n",
      "|    clip_fraction        | 0.0938       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.67        |\n",
      "|    explained_variance   | 0.548        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.01e+04     |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | 0.000347     |\n",
      "|    value_loss           | 2.55e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31           |\n",
      "|    ep_rew_mean          | 704          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 32           |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 1498         |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022302242 |\n",
      "|    clip_fraction        | 0.0899       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.684       |\n",
      "|    explained_variance   | 0.537        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 9.56e+03     |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | 0.00178      |\n",
      "|    value_loss           | 2.5e+04      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.6         |\n",
      "|    ep_rew_mean          | 676          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 32           |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 1743         |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017269199 |\n",
      "|    clip_fraction        | 0.079        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.632       |\n",
      "|    explained_variance   | 0.517        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.39e+04     |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | 0.00132      |\n",
      "|    value_loss           | 2.69e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33.3        |\n",
      "|    ep_rew_mean          | 721         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 33          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 1982        |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003975453 |\n",
      "|    clip_fraction        | 0.0874      |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.625      |\n",
      "|    explained_variance   | 0.54        |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 9.88e+03    |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | 0.00143     |\n",
      "|    value_loss           | 2.51e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.4         |\n",
      "|    ep_rew_mean          | 687          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 33           |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 2220         |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014594191 |\n",
      "|    clip_fraction        | 0.0823       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.642       |\n",
      "|    explained_variance   | 0.528        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.74e+04     |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | 0.00234      |\n",
      "|    value_loss           | 2.61e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 33           |\n",
      "|    ep_rew_mean          | 718          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 33           |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 2476         |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032658358 |\n",
      "|    clip_fraction        | 0.0923       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.634       |\n",
      "|    explained_variance   | 0.535        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 7.94e+03     |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | 0.00163      |\n",
      "|    value_loss           | 2.62e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 33.6         |\n",
      "|    ep_rew_mean          | 767          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 33           |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 2727         |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027197497 |\n",
      "|    clip_fraction        | 0.0865       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.607       |\n",
      "|    explained_variance   | 0.524        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.48e+04     |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | -0.000246    |\n",
      "|    value_loss           | 2.59e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.9         |\n",
      "|    ep_rew_mean          | 740          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 32           |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 2981         |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027368711 |\n",
      "|    clip_fraction        | 0.0761       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.55        |\n",
      "|    explained_variance   | 0.506        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.59e+04     |\n",
      "|    n_updates            | 500          |\n",
      "|    policy_gradient_loss | 0.00182      |\n",
      "|    value_loss           | 2.57e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29.9         |\n",
      "|    ep_rew_mean          | 729          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 32           |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 3238         |\n",
      "|    total_timesteps      | 106496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019244639 |\n",
      "|    clip_fraction        | 0.0691       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.507       |\n",
      "|    explained_variance   | 0.522        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.64e+04     |\n",
      "|    n_updates            | 510          |\n",
      "|    policy_gradient_loss | 0.00176      |\n",
      "|    value_loss           | 2.55e+04     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x22c5ec0cc40>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = VizDoomGym(config=\"github\\ViZDoom\\scenarios\\deadly_corridor_level_4.cfg\", render=False)\n",
    "model.set_env(env)\n",
    "model.learn(total_timesteps=100000, callback=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2650ced7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Logging to ./logs/log_corridor\\PPO_5\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 17       |\n",
      "|    ep_rew_mean     | 253      |\n",
      "| time/              |          |\n",
      "|    fps             | 35       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 233      |\n",
      "|    total_timesteps | 8192     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 17.3        |\n",
      "|    ep_rew_mean          | 273         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 33          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 482         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038006414 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.582      |\n",
      "|    explained_variance   | 0.0423      |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 1.57e+04    |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | 0.00476     |\n",
      "|    value_loss           | 3.13e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 16.5         |\n",
      "|    ep_rew_mean          | 271          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 33           |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 732          |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031619086 |\n",
      "|    clip_fraction        | 0.0842       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.515       |\n",
      "|    explained_variance   | 0.491        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.61e+04     |\n",
      "|    n_updates            | 540          |\n",
      "|    policy_gradient_loss | 0.00218      |\n",
      "|    value_loss           | 2.67e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 16.7        |\n",
      "|    ep_rew_mean          | 266         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 33          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 983         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001265689 |\n",
      "|    clip_fraction        | 0.0719      |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.515      |\n",
      "|    explained_variance   | 0.516       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 1e+04       |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | 0.00208     |\n",
      "|    value_loss           | 2.66e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 16.6         |\n",
      "|    ep_rew_mean          | 280          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 33           |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 1234         |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024325321 |\n",
      "|    clip_fraction        | 0.0741       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.49        |\n",
      "|    explained_variance   | 0.526        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.58e+04     |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | 0.00241      |\n",
      "|    value_loss           | 2.64e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 16.2         |\n",
      "|    ep_rew_mean          | 267          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 32           |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 1489         |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022074496 |\n",
      "|    clip_fraction        | 0.0665       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.42        |\n",
      "|    explained_variance   | 0.528        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.86e+04     |\n",
      "|    n_updates            | 570          |\n",
      "|    policy_gradient_loss | 0.00209      |\n",
      "|    value_loss           | 2.68e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 16.2         |\n",
      "|    ep_rew_mean          | 267          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 32           |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 1744         |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020652756 |\n",
      "|    clip_fraction        | 0.0599       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.424       |\n",
      "|    explained_variance   | 0.547        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.36e+04     |\n",
      "|    n_updates            | 580          |\n",
      "|    policy_gradient_loss | 0.00266      |\n",
      "|    value_loss           | 2.56e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 16.2        |\n",
      "|    ep_rew_mean          | 262         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 32          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 2004        |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002323344 |\n",
      "|    clip_fraction        | 0.0642      |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.406      |\n",
      "|    explained_variance   | 0.537       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 9.49e+03    |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | 0.00277     |\n",
      "|    value_loss           | 2.55e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 15.8         |\n",
      "|    ep_rew_mean          | 264          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 32           |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 2268         |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021545566 |\n",
      "|    clip_fraction        | 0.0634       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.361       |\n",
      "|    explained_variance   | 0.551        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.23e+04     |\n",
      "|    n_updates            | 600          |\n",
      "|    policy_gradient_loss | 0.00253      |\n",
      "|    value_loss           | 2.54e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 16           |\n",
      "|    ep_rew_mean          | 267          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 32           |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 2533         |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023905723 |\n",
      "|    clip_fraction        | 0.0616       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.345       |\n",
      "|    explained_variance   | 0.548        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.42e+04     |\n",
      "|    n_updates            | 610          |\n",
      "|    policy_gradient_loss | 0.00296      |\n",
      "|    value_loss           | 2.55e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 16.6        |\n",
      "|    ep_rew_mean          | 275         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 32          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 2791        |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001963214 |\n",
      "|    clip_fraction        | 0.0585      |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.344      |\n",
      "|    explained_variance   | 0.539       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 4.23e+03    |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | 0.00306     |\n",
      "|    value_loss           | 2.61e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 16.1        |\n",
      "|    ep_rew_mean          | 269         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 32          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 3039        |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001678821 |\n",
      "|    clip_fraction        | 0.0579      |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.364      |\n",
      "|    explained_variance   | 0.534       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 1.69e+04    |\n",
      "|    n_updates            | 630         |\n",
      "|    policy_gradient_loss | 0.00252     |\n",
      "|    value_loss           | 2.61e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 16           |\n",
      "|    ep_rew_mean          | 265          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 32           |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 3282         |\n",
      "|    total_timesteps      | 106496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015360345 |\n",
      "|    clip_fraction        | 0.0495       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.323       |\n",
      "|    explained_variance   | 0.544        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.01e+04     |\n",
      "|    n_updates            | 640          |\n",
      "|    policy_gradient_loss | 0.0018       |\n",
      "|    value_loss           | 2.61e+04     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x22c5ec0cc40>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = VizDoomGym(config=\"github\\ViZDoom\\scenarios\\deadly_corridor_level_5.cfg\", render=False)\n",
    "model.set_env(env)\n",
    "model.learn(total_timesteps=100000, callback=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e8403967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import eval policy to test agent\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f64a38d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load(r'train\\train_corridor\\best_model_530000.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360e9cf4",
   "metadata": {},
   "source": [
    "add config path to the Vizdoomgym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4cb57b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = VizDoomGym(config=\"github\\ViZDoom\\scenarios\\deadly_corridor_level_1.cfg\", render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "76dc1758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: 1311.47\n"
     ]
    }
   ],
   "source": [
    "mean_reward, _ = evaluate_policy(model, env, n_eval_episodes=10)\n",
    "print(f\"Mean reward: {mean_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "61ecad0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 finished with total reward: 1104.0857696533203\n",
      "Episode 2 finished with total reward: 909.4357147216797\n",
      "Episode 3 finished with total reward: 1736.6727142333984\n",
      "Episode 4 finished with total reward: 624.3687896728516\n",
      "Episode 5 finished with total reward: 1657.4813385009766\n"
     ]
    }
   ],
   "source": [
    "for episode in range(5):\n",
    "    obs, _ = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        time.sleep(0.05)  # Adjust the sleep time as needed\n",
    "        total_reward += reward\n",
    "    print(f\"Episode {episode + 1} finished with total reward: {total_reward}\")\n",
    "    time.sleep(2)  # Pause between episodes\n",
    "\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
