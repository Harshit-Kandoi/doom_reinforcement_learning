{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acfa1c81",
   "metadata": {},
   "source": [
    "1. Getting VizDoom Up and Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2299309a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: vizdoom in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.2.4)\n",
      "Requirement already satisfied: pygame>=2.1.3 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from vizdoom) (2.6.1)\n",
      "Requirement already satisfied: gymnasium>=0.28.0 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from vizdoom) (1.1.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from vizdoom) (2.2.5)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\kando\\appdata\\roaming\\python\\python310\\site-packages (from gymnasium>=0.28.0->vizdoom) (4.13.2)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gymnasium>=0.28.0->vizdoom) (0.0.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gymnasium>=0.28.0->vizdoom) (3.1.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install vizdoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48139cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'ViZDoom' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!cd github & git clone https://github.com/Farama-Foundation/ViZDoom.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3ac7f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import visdoom for game env\n",
    "from vizdoom import *\n",
    "# Import random for action sampling\n",
    "import random\n",
    "# Import time for sleeping\n",
    "import time\n",
    "# Import numpy for identity matrix creation\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3aaf11ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Game Setup\n",
    "game = DoomGame()\n",
    "# Set the game configuration file\n",
    "game.load_config(\"github/ViZDoom/scenarios/basic.cfg\")\n",
    "# Set the game scenario\n",
    "game.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b745ac62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the set of actions that the agent can take in the environment\n",
    "actions = np.identity(3, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97860173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Result: -370.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Result: -370.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Result: -380.0\n",
      "Reward:  -4.0\n",
      "Reward:  99.0\n",
      "Result: 95.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Result: -365.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Result: -375.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Result: -365.0\n",
      "Reward:  -4.0\n",
      "Reward:  99.0\n",
      "Result: 95.0\n",
      "Reward:  -4.0\n",
      "Reward:  99.0\n",
      "Result: 95.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -9.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Reward:  -4.0\n",
      "Result: -365.0\n"
     ]
    }
   ],
   "source": [
    "episode = 10\n",
    "for episode in range(episode):\n",
    "    # Start the game\n",
    "    game.new_episode()\n",
    "    # Run the game until it is over\n",
    "    while not game.is_episode_finished():\n",
    "        # Get the state of the game\n",
    "        state = game.get_state()\n",
    "        # Get the current frame from the state\n",
    "        frame = state.screen_buffer\n",
    "        # Sample a random action from the action space\n",
    "        action = random.choice(actions)\n",
    "        # Get the current reward from the state\n",
    "        info = state.game_variables[0]\n",
    "        # Perform the action in the game environment\n",
    "        reward = game.make_action(action, 4)\n",
    "        # Print the reward\n",
    "        print(\"Reward: \", reward)\n",
    "        # Sleep for a short time to control the speed of the agent's actions\n",
    "        time.sleep(0.1)\n",
    "    print('Result:', game.get_total_reward())\n",
    "    time.sleep(2)\n",
    "# Close the game when done\n",
    "game.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47822af7",
   "metadata": {},
   "source": [
    "2. Converting it to a Gym Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8657e71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: gymnasium in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gymnasium) (2.2.5)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\kando\\appdata\\roaming\\python\\python310\\site-packages (from gymnasium) (4.13.2)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gymnasium) (0.0.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gymnasium) (3.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install gymnasium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "901849dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: opencv-python in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from opencv-python) (2.2.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56510063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: pip in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (23.0.1)\n",
      "Collecting pip\n",
      "  Downloading pip-25.1.1-py3-none-any.whl (1.8 MB)\n",
      "     ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "     -- ------------------------------------- 0.1/1.8 MB 1.1 MB/s eta 0:00:02\n",
      "     --- ------------------------------------ 0.1/1.8 MB 1.1 MB/s eta 0:00:02\n",
      "     ----- ---------------------------------- 0.3/1.8 MB 1.4 MB/s eta 0:00:02\n",
      "     ------ --------------------------------- 0.3/1.8 MB 1.3 MB/s eta 0:00:02\n",
      "     ------------ --------------------------- 0.6/1.8 MB 2.0 MB/s eta 0:00:01\n",
      "     ------------- -------------------------- 0.6/1.8 MB 1.9 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 0.8/1.8 MB 2.2 MB/s eta 0:00:01\n",
      "     -------------------- ------------------- 0.9/1.8 MB 2.3 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 1.2/1.8 MB 2.6 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 1.3/1.8 MB 2.6 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 1.5/1.8 MB 2.9 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 1.7/1.8 MB 2.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.8/1.8 MB 3.0 MB/s eta 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: To modify pip, please run the following command:\n",
      "C:\\Users\\kando\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: matplotlib in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.10.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kando\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (2.2.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\kando\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kando\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install matplotlib --no-cache-dir --index-url https://pypi.org/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75448346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: torch in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.7.0+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.22.0+cu118)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.7.0+cu118)\n",
      "Requirement already satisfied: networkx in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\kando\\appdata\\roaming\\python\\python310\\site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (11.2.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (2.2.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4197547b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: stable-baselines3[extra] in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stable-baselines3[extra]) (2.2.3)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stable-baselines3[extra]) (3.1.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stable-baselines3[extra]) (3.10.1)\n",
      "Requirement already satisfied: torch<3.0,>=2.3 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stable-baselines3[extra]) (2.7.0+cu118)\n",
      "Requirement already satisfied: gymnasium<1.2.0,>=0.29.1 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stable-baselines3[extra]) (1.1.1)\n",
      "Requirement already satisfied: numpy<3.0,>=1.20 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stable-baselines3[extra]) (2.2.5)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stable-baselines3[extra]) (4.11.0.86)\n",
      "Requirement already satisfied: rich in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stable-baselines3[extra]) (14.0.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\kando\\appdata\\roaming\\python\\python310\\site-packages (from stable-baselines3[extra]) (7.0.0)\n",
      "Requirement already satisfied: pygame in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stable-baselines3[extra]) (2.6.1)\n",
      "Requirement already satisfied: tensorboard>=2.9.1 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stable-baselines3[extra]) (2.19.0)\n",
      "Requirement already satisfied: pillow in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stable-baselines3[extra]) (11.2.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stable-baselines3[extra]) (4.67.1)\n",
      "Requirement already satisfied: ale-py>=0.9.0 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stable-baselines3[extra]) (0.11.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\kando\\appdata\\roaming\\python\\python310\\site-packages (from ale-py>=0.9.0->stable-baselines3[extra]) (4.13.2)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gymnasium<1.2.0,>=0.29.1->stable-baselines3[extra]) (0.0.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (65.5.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.2.2)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.71.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.1.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.8)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (6.30.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\kando\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (25.0)\n",
      "Requirement already satisfied: six>1.9 in c:\\users\\kando\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.17.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.1.6)\n",
      "Requirement already satisfied: networkx in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.4.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.18.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (2025.3.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (1.14.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (4.57.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (0.12.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (3.2.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (1.4.8)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\kando\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib->stable-baselines3[extra]) (2.9.0.post0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (1.3.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->stable-baselines3[extra]) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->stable-baselines3[extra]) (2025.2)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\kando\\appdata\\roaming\\python\\python310\\site-packages (from rich->stable-baselines3[extra]) (2.19.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rich->stable-baselines3[extra]) (3.0.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\kando\\appdata\\roaming\\python\\python310\\site-packages (from tqdm->stable-baselines3[extra]) (0.4.6)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy>=1.13.3->torch<3.0,>=2.3->stable-baselines3[extra]) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\kando\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install stable-baselines3[extra]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06810963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import environment for OpenAI Gym\n",
    "import gymnasium as gym\n",
    "from gym import Env\n",
    "from gym import spaces\n",
    "from gym.spaces import Discrete, Box\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from stable_baselines3.common.env_checker import check_env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "db66899d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "import cv2\n",
    "from vizdoom import DoomGame\n",
    "\n",
    "class VizDoomGym(gym.Env):\n",
    "    def __init__(self, render=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.game = DoomGame()\n",
    "        self.game.load_config(\"github/ViZDoom/scenarios/basic.cfg\")\n",
    "        self.game.set_window_visible(render)\n",
    "        self.game.init()\n",
    "\n",
    "        # Gymnasium expects these to be from gymnasium.spaces\n",
    "        self.observation_space = spaces.Box(low=0, high=255, shape=(100, 160, 1), dtype=np.uint8)\n",
    "        self.action_space = spaces.Discrete(3)\n",
    "\n",
    "    def step(self, action):\n",
    "        actions = np.identity(3, dtype=np.uint8)\n",
    "        reward = self.game.make_action(actions[action], 4)\n",
    "\n",
    "        done = self.game.is_episode_finished()\n",
    "        truncated = False  # No time limit-based truncation\n",
    "        if not done and self.game.get_state():\n",
    "            state = self.game.get_state().screen_buffer\n",
    "            state = self.grayscale(state)\n",
    "            ammo = self.game.get_state().game_variables[0]\n",
    "            info = {\"ammo\": ammo}\n",
    "        else:\n",
    "            state = np.zeros(self.observation_space.shape, dtype=np.uint8)\n",
    "            info = {}\n",
    "\n",
    "        return state, reward, done, truncated, info\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "\n",
    "        if not self.game.is_running():\n",
    "            self.game.init()\n",
    "\n",
    "        self.game.new_episode()\n",
    "\n",
    "        state = self.game.get_state()\n",
    "        if state is None:\n",
    "            raise RuntimeError(\"Failed to get initial game state.\")\n",
    "\n",
    "        return self.grayscale(state.screen_buffer), {}\n",
    "\n",
    "\n",
    "    def render(self):\n",
    "        pass  # You can implement frame rendering if needed\n",
    "\n",
    "    def close(self):\n",
    "        self.game.close()\n",
    "\n",
    "    def grayscale(self, observation):\n",
    "        gray = cv2.cvtColor(np.moveaxis(observation, 0, -1), cv2.COLOR_BGR2GRAY)\n",
    "        resize = cv2.resize(gray, (160, 100), interpolation=cv2.INTER_CUBIC)\n",
    "        state = np.reshape(resize, (100, 160, 1))  # Fixed shape\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b5960c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.env_checker import check_env\n",
    "\n",
    "env = VizDoomGym(render=True)\n",
    "check_env(env)  # Should pass with no errors now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d780115",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "765385d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31969eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import os for file navigation\n",
    "import os\n",
    "#Import callback class from sb3\n",
    "from stable_baselines3.common.callbacks import BaseCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49d2df3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainAndLoggingCallback(BaseCallback):\n",
    "    \n",
    "    def __init__(self, check_freq, save_path, verbose=1):\n",
    "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "        \n",
    "    def _init_callback(self):\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "            \n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path, 'best_model')\n",
    "            self.model.save(model_path)\n",
    "            \n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "185ca1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = './train/train_basic'\n",
    "LOG_DIR = './logs/log_basic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db3696f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = TrainAndLoggingCallback(check_freq=10000, save_path=CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6228736",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e2cd83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cee1b9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render = false\n",
    "env = VizDoomGym()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e0ac2bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "model = PPO(\"CnnPolicy\", env, verbose=1, learning_rate=0.0001, tensorboard_log=LOG_DIR, n_steps=2048)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcc43a8",
   "metadata": {},
   "source": [
    "# Temperaraly closed the reinforcement learning due to no significant improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a00772dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./logs/log_basic\\PPO_3\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32       |\n",
      "|    ep_rew_mean     | -78.4    |\n",
      "| time/              |          |\n",
      "|    fps             | 34       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 59       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 27.4         |\n",
      "|    ep_rew_mean          | -49          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 18           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 215          |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059408443 |\n",
      "|    clip_fraction        | 0.113        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.000338     |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.04e+03     |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | 0.000657     |\n",
      "|    value_loss           | 2.63e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.8        |\n",
      "|    ep_rew_mean          | -64.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 308         |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024925753 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.0886      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.31e+03    |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00562    |\n",
      "|    value_loss           | 3.49e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 27.6        |\n",
      "|    ep_rew_mean          | -47.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 21          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 379         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012997793 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.267       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.19e+03    |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -4.22e-05   |\n",
      "|    value_loss           | 3.15e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 22.8        |\n",
      "|    ep_rew_mean          | -19.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 23          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 438         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030497598 |\n",
      "|    clip_fraction        | 0.329       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0.414       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.64e+03    |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | 0.00503     |\n",
      "|    value_loss           | 3.16e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 26.5        |\n",
      "|    ep_rew_mean          | -46.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 24          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 494         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017338082 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.984      |\n",
      "|    explained_variance   | 0.487       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 2.51e+03    |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | 0.00357     |\n",
      "|    value_loss           | 3.39e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 18.1        |\n",
      "|    ep_rew_mean          | 3.24        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 25          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 551         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009389259 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.95       |\n",
      "|    explained_variance   | 0.495       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.98e+03    |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | 0.00277     |\n",
      "|    value_loss           | 3.36e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 23.1       |\n",
      "|    ep_rew_mean          | -24.9      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 26         |\n",
      "|    iterations           | 8          |\n",
      "|    time_elapsed         | 607        |\n",
      "|    total_timesteps      | 16384      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01691949 |\n",
      "|    clip_fraction        | 0.216      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.989     |\n",
      "|    explained_variance   | 0.653      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 1.07e+03   |\n",
      "|    n_updates            | 70         |\n",
      "|    policy_gradient_loss | 0.00803    |\n",
      "|    value_loss           | 2.81e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 13.1        |\n",
      "|    ep_rew_mean          | 40.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 670         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013824085 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.963      |\n",
      "|    explained_variance   | 0.627       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.1e+03     |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | 0.00872     |\n",
      "|    value_loss           | 3.11e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 12          |\n",
      "|    ep_rew_mean          | 43.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 28          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 729         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019104581 |\n",
      "|    clip_fraction        | 0.348       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.937      |\n",
      "|    explained_variance   | 0.414       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 2.4e+03     |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | 0.00776     |\n",
      "|    value_loss           | 4.44e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.47        |\n",
      "|    ep_rew_mean          | 55.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 28          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 795         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.053834155 |\n",
      "|    clip_fraction        | 0.409       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.872      |\n",
      "|    explained_variance   | 0.354       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 931         |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | 0.0096      |\n",
      "|    value_loss           | 1.97e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 7.81       |\n",
      "|    ep_rew_mean          | 65.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 28         |\n",
      "|    iterations           | 12         |\n",
      "|    time_elapsed         | 858        |\n",
      "|    total_timesteps      | 24576      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03377403 |\n",
      "|    clip_fraction        | 0.314      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.762     |\n",
      "|    explained_variance   | 0.654      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 1.01e+03   |\n",
      "|    n_updates            | 110        |\n",
      "|    policy_gradient_loss | 0.00335    |\n",
      "|    value_loss           | 1.89e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 6.12        |\n",
      "|    ep_rew_mean          | 74.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 28          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 923         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044171687 |\n",
      "|    clip_fraction        | 0.335       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.683      |\n",
      "|    explained_variance   | 0.79        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 737         |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | 0.0116      |\n",
      "|    value_loss           | 964         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 5.05       |\n",
      "|    ep_rew_mean          | 81.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 29         |\n",
      "|    iterations           | 14         |\n",
      "|    time_elapsed         | 988        |\n",
      "|    total_timesteps      | 28672      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04375666 |\n",
      "|    clip_fraction        | 0.302      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.528     |\n",
      "|    explained_variance   | 0.508      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 252        |\n",
      "|    n_updates            | 130        |\n",
      "|    policy_gradient_loss | 0.0243     |\n",
      "|    value_loss           | 375        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.66        |\n",
      "|    ep_rew_mean          | 78.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 29          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 1053        |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046096656 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.554      |\n",
      "|    explained_variance   | 0.419       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 188         |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | 0.0508      |\n",
      "|    value_loss           | 354         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.05        |\n",
      "|    ep_rew_mean          | 80.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 29          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 1110        |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042941436 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.489      |\n",
      "|    explained_variance   | 0.357       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 242         |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | 0.0169      |\n",
      "|    value_loss           | 533         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4.84       |\n",
      "|    ep_rew_mean          | 81.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 29         |\n",
      "|    iterations           | 17         |\n",
      "|    time_elapsed         | 1170       |\n",
      "|    total_timesteps      | 34816      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.13380834 |\n",
      "|    clip_fraction        | 0.267      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.33      |\n",
      "|    explained_variance   | 0.53       |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 78.4       |\n",
      "|    n_updates            | 160        |\n",
      "|    policy_gradient_loss | 0.024      |\n",
      "|    value_loss           | 282        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.26        |\n",
      "|    ep_rew_mean          | 78          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 29          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 1229        |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.050743163 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.391      |\n",
      "|    explained_variance   | 0.492       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 70.4        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | 0.0414      |\n",
      "|    value_loss           | 196         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 5.6        |\n",
      "|    ep_rew_mean          | 77.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 30         |\n",
      "|    iterations           | 19         |\n",
      "|    time_elapsed         | 1294       |\n",
      "|    total_timesteps      | 38912      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22705881 |\n",
      "|    clip_fraction        | 0.334      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.355     |\n",
      "|    explained_variance   | 0.445      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 180        |\n",
      "|    n_updates            | 180        |\n",
      "|    policy_gradient_loss | 0.0725     |\n",
      "|    value_loss           | 428        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 4.97      |\n",
      "|    ep_rew_mean          | 81.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 30        |\n",
      "|    iterations           | 20        |\n",
      "|    time_elapsed         | 1360      |\n",
      "|    total_timesteps      | 40960     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0731514 |\n",
      "|    clip_fraction        | 0.205     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.285    |\n",
      "|    explained_variance   | 0.751     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 283       |\n",
      "|    n_updates            | 190       |\n",
      "|    policy_gradient_loss | 0.00863   |\n",
      "|    value_loss           | 580       |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.15        |\n",
      "|    ep_rew_mean          | 85.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 30          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 1431        |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030625867 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.298      |\n",
      "|    explained_variance   | 0.861       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 316         |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | 0.0114      |\n",
      "|    value_loss           | 590         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.95        |\n",
      "|    ep_rew_mean          | 86.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 30          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 1497        |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044119082 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.251      |\n",
      "|    explained_variance   | 0.732       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 74.1        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | 0.0253      |\n",
      "|    value_loss           | 240         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 3.84       |\n",
      "|    ep_rew_mean          | 87.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 30         |\n",
      "|    iterations           | 23         |\n",
      "|    time_elapsed         | 1567       |\n",
      "|    total_timesteps      | 47104      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06249146 |\n",
      "|    clip_fraction        | 0.168      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.261     |\n",
      "|    explained_variance   | 0.434      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 78.5       |\n",
      "|    n_updates            | 220        |\n",
      "|    policy_gradient_loss | 0.0285     |\n",
      "|    value_loss           | 270        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.83        |\n",
      "|    ep_rew_mean          | 82.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 30          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 1635        |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031665675 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.255      |\n",
      "|    explained_variance   | 0.478       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 25.5        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | 0.0429      |\n",
      "|    value_loss           | 81.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4.54       |\n",
      "|    ep_rew_mean          | 84.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 30         |\n",
      "|    iterations           | 25         |\n",
      "|    time_elapsed         | 1701       |\n",
      "|    total_timesteps      | 51200      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07245814 |\n",
      "|    clip_fraction        | 0.146      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.215     |\n",
      "|    explained_variance   | 0.497      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 93.5       |\n",
      "|    n_updates            | 240        |\n",
      "|    policy_gradient_loss | 0.027      |\n",
      "|    value_loss           | 242        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.42        |\n",
      "|    ep_rew_mean          | 84.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 30          |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 1763        |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.053712435 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.22       |\n",
      "|    explained_variance   | 0.4         |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 75.9        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | 0.0277      |\n",
      "|    value_loss           | 223         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4.44       |\n",
      "|    ep_rew_mean          | 84.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 30         |\n",
      "|    iterations           | 27         |\n",
      "|    time_elapsed         | 1833       |\n",
      "|    total_timesteps      | 55296      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04536009 |\n",
      "|    clip_fraction        | 0.169      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.193     |\n",
      "|    explained_variance   | 0.525      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 81.6       |\n",
      "|    n_updates            | 260        |\n",
      "|    policy_gradient_loss | 0.00236    |\n",
      "|    value_loss           | 199        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.32        |\n",
      "|    ep_rew_mean          | 84.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 30          |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 1900        |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036321964 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.196      |\n",
      "|    explained_variance   | 0.647       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 32.8        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | 0.0315      |\n",
      "|    value_loss           | 80.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.8         |\n",
      "|    ep_rew_mean          | 87.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 30          |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 1962        |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036372997 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.156      |\n",
      "|    explained_variance   | 0.572       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 24.7        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | 0.0171      |\n",
      "|    value_loss           | 107         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.33        |\n",
      "|    ep_rew_mean          | 85.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 30          |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 2018        |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025124514 |\n",
      "|    clip_fraction        | 0.092       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.17       |\n",
      "|    explained_variance   | 0.654       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 26.4        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | 0.0127      |\n",
      "|    value_loss           | 78.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4.1        |\n",
      "|    ep_rew_mean          | 85.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 30         |\n",
      "|    iterations           | 31         |\n",
      "|    time_elapsed         | 2072       |\n",
      "|    total_timesteps      | 63488      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12618938 |\n",
      "|    clip_fraction        | 0.179      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.174     |\n",
      "|    explained_variance   | 0.505      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 72.2       |\n",
      "|    n_updates            | 300        |\n",
      "|    policy_gradient_loss | 0.0145     |\n",
      "|    value_loss           | 114        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.26        |\n",
      "|    ep_rew_mean          | 85.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 30          |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 2128        |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046915542 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.144      |\n",
      "|    explained_variance   | 0.631       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 14.9        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | 0.00775     |\n",
      "|    value_loss           | 77          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4.09       |\n",
      "|    ep_rew_mean          | 86.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 30         |\n",
      "|    iterations           | 33         |\n",
      "|    time_elapsed         | 2186       |\n",
      "|    total_timesteps      | 67584      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02982797 |\n",
      "|    clip_fraction        | 0.0968     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.124     |\n",
      "|    explained_variance   | 0.675      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 47.1       |\n",
      "|    n_updates            | 320        |\n",
      "|    policy_gradient_loss | -0.002     |\n",
      "|    value_loss           | 68.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.73        |\n",
      "|    ep_rew_mean          | 87.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 30          |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 2263        |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017986942 |\n",
      "|    clip_fraction        | 0.093       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.149      |\n",
      "|    explained_variance   | 0.821       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 21.1        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | 0.04        |\n",
      "|    value_loss           | 25.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.16        |\n",
      "|    ep_rew_mean          | 86.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 30          |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 2334        |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.052710712 |\n",
      "|    clip_fraction        | 0.0877      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.116      |\n",
      "|    explained_variance   | 0.594       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 68.6        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | 0.00773     |\n",
      "|    value_loss           | 78.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.39        |\n",
      "|    ep_rew_mean          | 85.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 30          |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 2404        |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021615926 |\n",
      "|    clip_fraction        | 0.0586      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.143      |\n",
      "|    explained_variance   | 0.775       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 26.5        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | 0.0198      |\n",
      "|    value_loss           | 37.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4.52       |\n",
      "|    ep_rew_mean          | 84.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 30         |\n",
      "|    iterations           | 37         |\n",
      "|    time_elapsed         | 2470       |\n",
      "|    total_timesteps      | 75776      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02712552 |\n",
      "|    clip_fraction        | 0.0688     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.114     |\n",
      "|    explained_variance   | 0.715      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 5.69       |\n",
      "|    n_updates            | 360        |\n",
      "|    policy_gradient_loss | 0.000289   |\n",
      "|    value_loss           | 55.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.07        |\n",
      "|    ep_rew_mean          | 86.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 30          |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 2545        |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025232065 |\n",
      "|    clip_fraction        | 0.0829      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0964     |\n",
      "|    explained_variance   | 0.736       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 19.3        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | 0.00374     |\n",
      "|    value_loss           | 47.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.17        |\n",
      "|    ep_rew_mean          | 86.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 30          |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 2624        |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020494748 |\n",
      "|    clip_fraction        | 0.0669      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.113      |\n",
      "|    explained_variance   | 0.693       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 76.5        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | 0.03        |\n",
      "|    value_loss           | 48.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.94        |\n",
      "|    ep_rew_mean          | 86.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 30          |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 2700        |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031576846 |\n",
      "|    clip_fraction        | 0.0831      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0964     |\n",
      "|    explained_variance   | 0.689       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 4.41        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | 0.0192      |\n",
      "|    value_loss           | 52.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.55        |\n",
      "|    ep_rew_mean          | 88.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 30          |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 2769        |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.053182952 |\n",
      "|    clip_fraction        | 0.0772      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0757     |\n",
      "|    explained_variance   | 0.766       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 12.2        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | 0.0183      |\n",
      "|    value_loss           | 35.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.31        |\n",
      "|    ep_rew_mean          | 85.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 30          |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 2834        |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005304191 |\n",
      "|    clip_fraction        | 0.0549      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0916     |\n",
      "|    explained_variance   | 0.846       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 2.37        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | 0.0116      |\n",
      "|    value_loss           | 21.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 3.82       |\n",
      "|    ep_rew_mean          | 87.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 30         |\n",
      "|    iterations           | 43         |\n",
      "|    time_elapsed         | 2902       |\n",
      "|    total_timesteps      | 88064      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04950267 |\n",
      "|    clip_fraction        | 0.0547     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0856    |\n",
      "|    explained_variance   | 0.775      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 25.5       |\n",
      "|    n_updates            | 420        |\n",
      "|    policy_gradient_loss | 0.0236     |\n",
      "|    value_loss           | 34.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.74        |\n",
      "|    ep_rew_mean          | 87.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 30          |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 2969        |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024977745 |\n",
      "|    clip_fraction        | 0.0737      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0817     |\n",
      "|    explained_variance   | 0.768       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 5.89        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | 0.0278      |\n",
      "|    value_loss           | 36.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[82], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kando\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:311\u001b[0m, in \u001b[0;36mPPO.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfPPO,\n\u001b[0;32m    304\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    309\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    310\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfPPO:\n\u001b[1;32m--> 311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kando\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:324\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[1;32m--> 324\u001b[0m     continue_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_rollout_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m continue_training:\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kando\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:218\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.collect_rollouts\u001b[1;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    214\u001b[0m         \u001b[38;5;66;03m# Otherwise, clip the actions to avoid out of bound error\u001b[39;00m\n\u001b[0;32m    215\u001b[0m         \u001b[38;5;66;03m# as we are sampling from an unbounded Gaussian distribution\u001b[39;00m\n\u001b[0;32m    216\u001b[0m         clipped_actions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(actions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mlow, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mhigh)\n\u001b[1;32m--> 218\u001b[0m new_obs, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclipped_actions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mnum_envs\n\u001b[0;32m    222\u001b[0m \u001b[38;5;66;03m# Give access to local variables\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kando\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py:222\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[1;34m(self, actions)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;124;03mStep the environments with the given action\u001b[39;00m\n\u001b[0;32m    217\u001b[0m \n\u001b[0;32m    218\u001b[0m \u001b[38;5;124;03m:param actions: the action\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;124;03m:return: observation, reward, done, information\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_async(actions)\n\u001b[1;32m--> 222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kando\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\vec_transpose.py:97\u001b[0m, in \u001b[0;36mVecTransposeImage.step_wait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VecEnvStepReturn:\n\u001b[1;32m---> 97\u001b[0m     observations, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvenv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;66;03m# Transpose the terminal observations\u001b[39;00m\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, done \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dones):\n",
      "File \u001b[1;32mc:\\Users\\kando\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:71\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones[env_idx]:\n\u001b[0;32m     69\u001b[0m         \u001b[38;5;66;03m# save final observation where user can get it, then reset\u001b[39;00m\n\u001b[0;32m     70\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos[env_idx][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mterminal_observation\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m obs\n\u001b[1;32m---> 71\u001b[0m         obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_infos[env_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvs\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_obs(env_idx, obs)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obs_from_buf(), np\u001b[38;5;241m.\u001b[39mcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_rews), np\u001b[38;5;241m.\u001b[39mcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones), deepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos))\n",
      "File \u001b[1;32mc:\\Users\\kando\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stable_baselines3\\common\\monitor.py:83\u001b[0m, in \u001b[0;36mMonitor.reset\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected you to pass keyword argument \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m into reset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_reset_info[key] \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m---> 83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mreset(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[1;32mIn[65], line 39\u001b[0m, in \u001b[0;36mVizDoomGym.reset\u001b[1;34m(self, seed, options)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mreset\u001b[39m(\u001b[38;5;28mself\u001b[39m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mreset(seed\u001b[38;5;241m=\u001b[39mseed)\n\u001b[1;32m---> 39\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_episode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m     state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgame\u001b[38;5;241m.\u001b[39mget_state()\u001b[38;5;241m.\u001b[39mscreen_buffer\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrayscale(state), {}\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.learn(total_timesteps=100000, callback=callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e682a5e6",
   "metadata": {},
   "source": [
    "A piece of code if you want to further improve the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa865d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from stable_baselines3 import PPO\n",
    "\n",
    "# # Load existing best model\n",
    "# model = PPO.load(\"best_model.zip\", env=env)\n",
    "\n",
    "# # Continue training with more timesteps\n",
    "# model.learn(total_timesteps=1_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e8403967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import eval policy to test agent\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f64a38d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load(r'train\\train_basic\\best_model.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4cb57b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = VizDoomGym(render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "76dc1758",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kando\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: 88.72\n"
     ]
    }
   ],
   "source": [
    "mean_reward, _ = evaluate_policy(model, env, n_eval_episodes=100)\n",
    "print(f\"Mean reward: {mean_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "61ecad0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 finished with total reward: 71.0\n",
      "Episode 2 finished with total reward: 95.0\n",
      "Episode 3 finished with total reward: 95.0\n",
      "Episode 4 finished with total reward: 95.0\n",
      "Episode 5 finished with total reward: 95.0\n"
     ]
    }
   ],
   "source": [
    "for episode in range(5):\n",
    "    obs, _ = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        time.sleep(0.05)  # Adjust the sleep time as needed\n",
    "        total_reward += reward\n",
    "    print(f\"Episode {episode + 1} finished with total reward: {total_reward}\")\n",
    "    time.sleep(2)  # Pause between episodes\n",
    "\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
